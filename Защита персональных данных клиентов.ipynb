{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a51d4b2f",
   "metadata": {},
   "source": [
    "# Защита персональных данных клиентов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6086063",
   "metadata": {},
   "source": [
    "<b>Задача:</b> Разработать метод преобразования данных, благодаря которому будет сложно восстановить персональную информацию, при этом качество моделей машинного обучения не должно измениться. Проверка качества должна быть проведена с использованием модели линейной регрессии, написанной самостоятельно и обоснованной математически. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3211c9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afa9c69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9a065e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Пол</th>\n",
       "      <th>Возраст</th>\n",
       "      <th>Зарплата</th>\n",
       "      <th>Члены семьи</th>\n",
       "      <th>Страховые выплаты</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>49600.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>38000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>41700.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>26100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Пол  Возраст  Зарплата  Члены семьи  Страховые выплаты\n",
       "0    1     41.0   49600.0            1                  0\n",
       "1    0     46.0   38000.0            1                  1\n",
       "2    0     29.0   21000.0            0                  0\n",
       "3    0     21.0   41700.0            2                  0\n",
       "4    1     28.0   26100.0            0                  0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('insurance.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98df0fd8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3ad206",
   "metadata": {},
   "source": [
    "## Первичный анализ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bf44112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Размер датасета: 5000 записей на 5 признаков\n",
      "Обнаружено пропусков: 0\n",
      "Обнаружено дубликатов: 153\n",
      "\n",
      "   Пол  Возраст  Зарплата  Члены семьи  Страховые выплаты\n",
      "0    1     41.0   49600.0            1                  0\n",
      "1    0     46.0   38000.0            1                  1\n",
      "2    0     29.0   21000.0            0                  0\n",
      "3    0     21.0   41700.0            2                  0\n",
      "4    1     28.0   26100.0            0                  0\n"
     ]
    }
   ],
   "source": [
    "print(); print('Размер датасета:', data.shape[0], 'записей на', data.shape[1], 'признаков')\n",
    "print('Обнаружено пропусков:', data.isna().sum().sum())\n",
    "print('Обнаружено дубликатов:', data.duplicated().sum()); data = data.drop_duplicates()\n",
    "\n",
    "features = data.drop('Страховые выплаты', axis=1)\n",
    "target = data['Страховые выплаты']\n",
    "\n",
    "print(); print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2409a41",
   "metadata": {},
   "source": [
    "<b>Итог:</b> Проведя первичный анализ на маленьком датасете, не было обнаружено пропусков, но были выявлены и удалены 153 дубликата. В дальнейшем, избавление от полностью идентичных записей поможет модели машинного обучения избежать переобучения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4f5cf0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4b4aba",
   "metadata": {},
   "source": [
    "## Вывод формул"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22cfe7e",
   "metadata": {},
   "source": [
    "#### Линейная регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d8c98a",
   "metadata": {},
   "source": [
    "Задача обучения: $w = \\arg\\min_w MSE(Xw, y)$, минимизировать разницу между предсказанием и целевым признаком, следовательно $Xw = y$. Нам нужно найти вектор весов, чтобы расчитать важность признака. Другими словами, неважный признак будет иметь меньший вес и влиять меньше на так называемый target. Для нахождения $w$ вначале надо домножить обе части уравнения на $X^{-1}$:\n",
    "\n",
    "$$X^{-1}Xw=X^{-1}y$$\n",
    "\n",
    "Вспоминая, что $XX^{-1} = E$ (единичная матрика), а $Ew = w$, то получаем:\n",
    "\n",
    "$$w = X^{-1}y$$\n",
    "\n",
    "С точки зрения математики мы получили верное уравнение, но на практике не найдется решения, если $X$ не является квадратной матрицей (mxm), что стремится к нулю. Но домножив уравнение на обратную матриуц, мы получим так необходимую квадратную матрицу:\n",
    "\n",
    "$$X^TXw=X^Ty$$\n",
    "\n",
    "Теперь при $w$ стоит множетель, от которого нужно избавиться. Для этого надо умножить обе части уравнения на этот множитель, но обратный:\n",
    "\n",
    "$$(X^TX)^{-1}(X^TX)w=(X^TX)^{-1}X^Ty$$\n",
    "\n",
    "Матрица умноженная на обратную матрицу исчезает и остается вектор весов, ради которого все затевалось.\n",
    "\n",
    "$$w=(X^TX)^{-1}X^Ty$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4d8c18",
   "metadata": {},
   "source": [
    "#### Алгоритм преобразования данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae522d7",
   "metadata": {},
   "source": [
    "Мы умножаем признаки размерностью $m$x$n$ на случайно сгенерированную обратимую матрицу размером $n$x$n$, а после обучения получаем предсказания $a'$ не отличимые от предсказаний без кодирования $a$. Значит надо доказать, что:\n",
    "\n",
    "$$a = Xw = XEw = XPP^{-1}w = (XP)P^{-1}w = (XP)w' = a'$$\n",
    "\n",
    "Умноженная матрица будет иметь вид $X \\times P$. Тогда фомула весов примет следующий вид:\n",
    "\n",
    "$$a' = (XP)w'$$\n",
    "\n",
    "$$w = (X^T X)^{-1} X^T y \\Rightarrow$$ \n",
    "\n",
    "$$w' = ((XP)^T XP)^{-1} (XP)^T y$$\n",
    "\n",
    "Получилась формула весов, которую мы подставляем в выведенную формулу предсказаний:\n",
    "\n",
    "$$w' = (X^T P^T XP)^{-1} P^T X^T y$$\n",
    "\n",
    "$$a' = XP(X^T P^T XP)^{-1} P^T X^T y$$\n",
    "\n",
    "Перемножать напрямую матрицы не стоит, поскольку для работы с формулой ее ответы должны быть в виде квадратной матрицы, поэтому сократим лишнее и получим:\n",
    "\n",
    "$$a' = XPP^{-1}(X^T X)^{-1} P^{T^{-1}}P^T X^T y \\Rightarrow$$ \n",
    "\n",
    "$$a' = X(X^T X)^{-1} X^T y$$\n",
    "\n",
    "Из формулы следует, что при умножении признаков на случайно сгенерированную обратимую матрицу размером $n$x$n$, мы получим такие же предсказания, как и без умножения, но данные клиента будут зашифрованы:\n",
    "\n",
    "$$a = Xw = (XP)w' = X(X^T X)^{-1} X^T y = a'$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab980d21",
   "metadata": {},
   "source": [
    "#### Гребневая регрессия (L2-регуляризация)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d51b79",
   "metadata": {},
   "source": [
    "Иногда получается, что детерминант матрицы равен нулю. Безусловно, шанс этого стремится к нулю, но все же, ему не равен. Если такое происходит, то линейная регрессия выдаст ошибку из-за невозможности рассчитать обратную матрицу. Для избежания этой ошибки к изначальной матрице прибавляется единичная матрица, что помогает избежать сразу двух проблем: нулевого детерминанта и линейной зависимости признаков (линейная зависимость признаков весьма нежелательна в модели линейной регрессии):\n",
    "\n",
    "$$\\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix} + \\begin{pmatrix} 1 & 2 & 0 \\\\ 1 & 2 & 0 \\\\ 1 & 2 & 0 \\end{pmatrix} = \\begin{pmatrix} 2 & 2 & 0 \\\\ 1 & 3 & 0 \\\\ 1 & 2 & 1 \\end{pmatrix}$$\n",
    "\n",
    "Исходя из этого, в новой формуле весов для обучения модели прибавляется единичная матрица:\n",
    "\n",
    "$$w=(X^TX+\\lambda I)^{-1}X^Ty$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87c7202",
   "metadata": {},
   "source": [
    "#### Метрика оценки R2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2e8c8c",
   "metadata": {},
   "source": [
    "Для расчета точности модели, мы возьмем метрику R2, которая покажет насколько наша модель лучше, чем постоянная базовая линия.\n",
    "\n",
    "$$R^2 = 1 - \\frac {\\sum^{n}_{i=1}(y_i - \\hat{y}_i)^2} {\\sum^{n}_{i=1}(y_i - \\bar{y})^2}$$\n",
    "\n",
    "$$\\sigma^2 = \\sum^n_{i=1} \\frac {(\\mu - x_i)^2}{n}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d45bba",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47798d42",
   "metadata": {},
   "source": [
    "## Доказательство"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04996bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# метрика r2 написанная вручную\n",
    "def r2 (target, predictions):\n",
    "    return 1 - (np.mean((target - predictions) ** 2) / np.var(target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663167b5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1690f1be",
   "metadata": {},
   "source": [
    "### До шифрования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5ad95a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    \n",
    "    def fit(self, features, target):\n",
    "        X = np.concatenate((np.ones((features.shape[0], 1)), features), axis=1)\n",
    "        y = target\n",
    "        w = np.dot(np.dot(np.linalg.inv(np.dot(X.T, X) + np.eye(features.shape[1] + 1)), X.T), y)\n",
    "        self.w = w[1:]\n",
    "        self.w0 = w[0]\n",
    "\n",
    "    def predict(self, features):\n",
    "        return np.dot(features, self.w) + self.w0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fbf05e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество модели: 0.43019523064161735\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression(); model.fit(features, target)\n",
    "print('Качество модели:', r2(target, model.predict(features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1294b0dd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09737bd3",
   "metadata": {},
   "source": [
    "### После шифрования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6a56641",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encryption (X):\n",
    "    \n",
    "    protective_matrix = np.random.randint(1, 10, (4,4))\n",
    "    encrypted_matrix = np.dot(X, protective_matrix)\n",
    "    \n",
    "    return encrypted_matrix\n",
    "\n",
    "features = encryption(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9223de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество модели: 0.43019523695347195\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression(); model.fit(features, target)\n",
    "print('Качество модели:', r2(target, model.predict(features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29c1f78",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef735806",
   "metadata": {},
   "source": [
    "<b>Вывод:</b> Были написаны вручную и обоснованы математически три алгоритма. Доказано, что данные до шифрования и после имеют одинаковые значения. И получена метрика 0.43, которая свидетельствует о превосходстве модели над константной."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
